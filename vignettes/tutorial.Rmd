---
title: "Project 3: PACKAGE_NAME Tutorial"
author: Vanessa Yang
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{PACKAGE_NAME Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction
This package is for project 3 for STAT302. It contains four functions: 
<p>
* my_t.test
* my_lm
* my_knn_cv
* my_rf_cv
</p>
These models analyze data and evaluate statistical models. It also containts a dataset my_gapminder taken from the gapminder package.
<br>


You can install my package through Github by typing in the console:
```{r install, eval=FALSE}
devtools::install_github("vanessaaaay/package302")
```


To begin, we need to load the following packages and the example dataset.
```{r setup}
library(package302)
library(magrittr)
library(ggplot2)
library(dplyr)
library(kableExtra)
data("my_gapminder")
```


## Tutorials
In the tutorial section, I will demonstrate how to use each function.

### my_t_test
Function *my_t.test}* can be used to perform a one-sample t-test. It's helpful when you want to test the null hypothesis. We are going to make some t-tests here by using **lifeExp**  variable from my_gapminder dataset.
<br>
Suppose I want to test the null hypothesis in which the mean value of lifeExp is 60. So we will set *mu = 60*.
```{r mu}
mu <- 60
```
And:
$$H_0: \mu = 60$$
We also want to set the significant level to 0.05.
$$\alpha = 0.05$$

**example 1 -- two.sided t-test:**
$$H_a: \mu \neq 60$$
```{r two.sided}
my_t.test(my_gapminder$lifeExp, "two.sided", mu)
```
From the output, we can see the t statistics, degree of freedom, p-value, and the alternative hypothesis. The p-value is greater than the significant level of 0.05, so we don't reject the null hypothesis.


**example 2 -- one.sided t-test (greater)**
```{r greater}
my_t.test(my_gapminder$lifeExp, "greater", mu)
```
We don't reject the null hypothesis because the p-value is greater than the significant level of 0.05.


**example 3 -- one.sided t-test (less)**
$$H_a: \mu < 60$$
```{r less}
my_t.test(my_gapminder$lifeExp, "less", mu)
```
The p-value for "less" is less than the significant level of 0.05. Thus, we reject the null hypothesis and accept the alternative hypothesis.


### my_lm
my_lm runs a linear regression model. we will perform a linear regression using **lifeExp** as our response variable and **gdpPercap** and **continent** as explanatory variables.
<br>

```{r my_lm, message=FALSE, warning=FALSE}
my_model <- my_lm(lifeExp ~ gdpPercap + continent, data = my_gapminder)
# display my_model
my_model
```
The coefficient for gdpPercap(`r my_model$Estimate[2]`) is positive, meaning that the lifeExp increases `r my_model$Estimate[2]` as gpdPercap increases one unit.


We can also have a hythothesis test on gdpPercap coefficient. 
<br>

We first need to set a $H_0$ and a $H_a$.
$$H_0: coef = 0$$
$$H_0: coef \neq 0$$
Then, we will test it using the significant level of 0.05.
$$ \alpha = 0.05$$
We can see that the p-value is smaller than the significant value, so we can reject the null hypothesis.


Next, we want to test the fit of the model.
```{r x and y}
object <- lifeExp ~ gdpPercap + continent
# extract the model 
model <- model.frame(object, my_gapminder)
# extract x 
x <- model.matrix(object, my_gapminder)
# extract y
y <- as.matrix(model.response(model))
```

We can visualize and compare the actual value and the fitted value.
```{r}
my_lifeExp <- x %*% my_model$Estimate + my_model$Std.Error
my_df <- data.frame("actual" = my_gapminder$lifeExp, "fitted" = my_lifeExp,
                    "color" = my_gapminder$continent) 
my_df %>%
  ggplot(aes(x = fitted, y = actual, color = color)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  labs(title = "Actual vs. Fitted Values", x = "Fitted Values", y = "Actual Values",
       color = "Continent") +
  theme(legend.justification = c("right", "top"))
```
<br>
we can see that the model fit with values in Europe and Oceania, but other continents have outliers. Therefore, it does not fit well with the data, and we may use other models.


